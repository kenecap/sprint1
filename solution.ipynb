{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4f1230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Чтение сырого файла: data\\tweets.txt\n",
      "2. Очистка текста...\n",
      "Готово. Получено 1596801 чистых строк.\n",
      "4. Сохранение файлов...\n",
      "\n",
      "Процесс завершен! Файлы сохранены:\n",
      "  - Обучающая выборка: data\\train.csv (1277440 строк)\n",
      "  - Валидационная выборка: data\\val.csv (159680 строк)\n",
      "  - Тестовая выборка: data\\test.csv (159681 строк)\n",
      "\n",
      "--- Пример данных из созданного train.csv ---\n",
      "                                                     text\n",
      "86449      or you could be like me work six days in a row\n",
      "989848                 good morning have a wonderful week\n",
      "869848  hope this works or a simple pic what a capacit...\n",
      "938814  just read the sweet message my best friend sen...\n",
      "75206   why is no one shopping am on my lunch isnt out...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.data_utils import load_and_clean_data\n",
    "\n",
    "data_dir = Path('./data/')\n",
    "raw_data_path = data_dir / 'tweets.txt'\n",
    "\n",
    "clean_df = load_and_clean_data(raw_data_path)\n",
    "\n",
    "\n",
    "train_df, temp_df = train_test_split(clean_df, test_size=0.2, random_state=42)\n",
    "\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "print(\"4. Сохранение файлов...\")\n",
    "train_path = data_dir / 'train.csv'\n",
    "val_path = data_dir / 'val.csv'\n",
    "test_path = data_dir / 'test.csv'\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "val_df.to_csv(val_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(\"\\nПроцесс завершен! Файлы сохранены:\")\n",
    "print(f\"  - Обучающая выборка: {train_path} ({len(train_df)} строк)\")\n",
    "print(f\"  - Валидационная выборка: {val_path} ({len(val_df)} строк)\")\n",
    "print(f\"  - Тестовая выборка: {test_path} ({len(test_df)} строк)\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Пример данных из созданного train.csv ---\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44839c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 20000\n",
      "DataLoader'ы готовы.\n",
      "Размер батча (вход): torch.Size([128, 26])\n",
      "Размер батча (цель): torch.Size([128, 26])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from src.next_token_dataset import TextDataset, PadCollate\n",
    "\n",
    "data_dir = Path('./data/')\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataset = TextDataset(file_path=data_dir / 'train.csv')\n",
    "\n",
    "vocab = train_dataset.word2idx\n",
    "pad_idx = vocab[train_dataset.pad_token]\n",
    "vocab_size = train_dataset.vocab_size\n",
    "\n",
    "val_dataset = TextDataset(file_path=data_dir / 'val.csv', vocab=vocab)\n",
    "test_dataset = TextDataset(file_path=data_dir / 'test.csv', vocab=vocab)\n",
    "\n",
    "collate_fn = PadCollate(pad_idx=pad_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"Размер словаря: {vocab_size}\")\n",
    "print(\"DataLoader'ы готовы.\")\n",
    "\n",
    "inputs, targets = next(iter(train_loader))\n",
    "print(f\"Размер батча (вход): {inputs.shape}\")\n",
    "print(f\"Размер батча (цель): {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c2aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель создана и успешно обработала один батч данных.\n",
      "Размер входа: torch.Size([128, 26])\n",
      "Размер выхода (логитов): torch.Size([128, 26, 20000])\n",
      "Ожидаемый размер выхода: (128, 26, 20000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.lstm_model import LSTMModel\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout_prob=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "\n",
    "inputs, targets = next(iter(train_loader))\n",
    "inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "output = model(inputs)\n",
    "\n",
    "print(\"Модель создана и успешно обработала один батч данных.\")\n",
    "print(f\"Размер входа: {inputs.shape}\")\n",
    "print(f\"Размер выхода (логитов): {output.shape}\")\n",
    "print(f\"Ожидаемый размер выхода: ({BATCH_SIZE}, {inputs.shape[1]}, {vocab_size})\")\n",
    "\n",
    "\n",
    "idx2word = train_dataset.idx2word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafeeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from src.lstm_train import train_loop\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 5 \n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_loop(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    device=device,\n",
    "    vocab=vocab,\n",
    "    idx2word=idx2word\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b1a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "model_path = Path('./models/best_lstm_model.pth')\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "\n",
    "test_prompts = [\n",
    "    \"i feel so\",\n",
    "    \"today is a\",\n",
    "    \"i want to\",\n",
    "    \"what are you\",\n",
    "    \"this is the\"\n",
    "]\n",
    "\n",
    "print(\"\\n--- Примеры генерации текста ---\")\n",
    "for prompt in test_prompts:\n",
    "    generated_text = model.generate(\n",
    "        start_seq=prompt,\n",
    "        max_len=15,\n",
    "        vocab=vocab,\n",
    "        idx2word=idx2word,\n",
    "        device=device\n",
    "    )\n",
    "    print(f\"PROMPT: '{prompt}'\")\n",
    "    print(f\"GENERATED: '{generated_text}'\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
